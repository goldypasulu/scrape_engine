# Tokopedia Scrape Engine

A production-grade, undetectable scraping engine specifically designed for Tokopedia (Indonesian E-commerce) with aggressive anti-bot protections.

## Features

- ğŸ›¡ï¸ **Stealth Mode**: puppeteer-extra-plugin-stealth with additional anti-detection measures
- ğŸ”„ **User Agent Rotation**: 20+ modern user agents with viewport matching
- ğŸŒ **Human-Like Behavior**: Random delays, variable scroll speeds, reading pauses
- ğŸ“œ **Smart Infinite Scroll**: Triggers lazy-loading without triggering bot detection
- ğŸ¯ **Resilient Selectors**: Uses stable `data-testid` attributes with fallback chains
- ğŸ“Š **Job Queue**: Redis-based BullMQ for scalable job processing
- ğŸ”§ **Concurrency Control**: Tunable browser instances and worker counts
- ğŸ“ **Structured Logging**: Pino-based JSON logging for production use

## Prerequisites

- Node.js >= 18.0.0
- Redis server (for BullMQ job queue)

## Installation

```bash
# Clone the repository
cd scrape_engine

# Install dependencies
npm install

# Copy environment configuration
cp .env.example .env

# Edit .env with your Redis configuration
```

## Configuration

Edit `.env` to configure the engine:

```bash
# Redis
REDIS_HOST=localhost
REDIS_PORT=6379

# Concurrency (tune based on CPU/RAM)
MAX_CONCURRENCY=2    # Browser instances
MAX_WORKERS=3        # Parallel job processing

# Scroll behavior
SCROLL_DELAY_MIN=800
SCROLL_DELAY_MAX=2000

# Timeouts
PAGE_TIMEOUT=60000
```

### Concurrency Tuning

| Setting | Low Resources | Medium | High Performance |
|---------|--------------|--------|------------------|
| `MAX_CONCURRENCY` | 1-2 | 3-4 | 5-8 |
| `MAX_WORKERS` | 2 | 3-5 | 5-10 |
| Memory per browser | ~300MB | ~400MB | ~500MB |

## Usage

### Start the Worker

```bash
# Start processing jobs from the queue
npm run worker

# Test initialization without processing
npm run worker -- --dry-run
```

### Enqueue Jobs

```bash
# Single keyword search
npm run enqueue -- --keyword "iphone 15"

# With custom page limit
npm run enqueue -- --keyword "laptop gaming" --pages 10

# Direct URL
npm run enqueue -- --url "https://www.tokopedia.com/search?q=laptop"

# Bulk jobs from file
npm run enqueue -- --bulk keywords.json
```

### Bulk Job File Format

```json
{
  "jobs": [
    { "keyword": "iphone 15", "maxPages": 5 },
    { "keyword": "samsung galaxy", "maxPages": 3 },
    { "url": "https://www.tokopedia.com/search?q=laptop" }
  ]
}
```

### Programmatic Usage

```javascript
import { 
  enqueueScrapeJob, 
  startWorker,
  getJobCounts 
} from './src/index.js';

// Start the worker
await startWorker();

// Enqueue a job
const job = await enqueueScrapeJob({
  keyword: 'iphone 15',
  maxPages: 5,
});

console.log('Job ID:', job.id);

// Check queue status
const counts = await getJobCounts();
console.log('Queue:', counts);
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Producer      â”‚â”€â”€â”€â”€â–¶â”‚   Redis Queue   â”‚â”€â”€â”€â”€â–¶â”‚   Worker(s)     â”‚
â”‚  (enqueue-job)  â”‚     â”‚   (BullMQ)      â”‚     â”‚  (start-worker) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                                         â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚  Puppeteer Cluster  â”‚
                                              â”‚   + Stealth Plugin  â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚   Cheerio Parser    â”‚
                                              â”‚   + Data Transform  â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚    JSON Output      â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
scrape_engine/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.js              # Main entry & exports
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ index.js          # Environment configuration
â”‚   â”‚   â”œâ”€â”€ selectors.js      # Stable DOM selectors
â”‚   â”‚   â””â”€â”€ user-agents.js    # User agent rotation
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ cluster.js        # Puppeteer cluster setup
â”‚   â”‚   â”œâ”€â”€ stealth.js        # Anti-detection config
â”‚   â”‚   â””â”€â”€ browser-utils.js  # Page interaction helpers
â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”œâ”€â”€ auto-scroll.js    # Human-like scrolling
â”‚   â”‚   â”œâ”€â”€ dom-selector.js   # Resilient selectors
â”‚   â”‚   â””â”€â”€ product-scraper.js # Main scraping logic
â”‚   â”œâ”€â”€ parser/
â”‚   â”‚   â”œâ”€â”€ html-parser.js    # Cheerio extraction
â”‚   â”‚   â””â”€â”€ data-transformer.js # Data cleaning
â”‚   â”œâ”€â”€ queue/
â”‚   â”‚   â”œâ”€â”€ connection.js     # Redis connection
â”‚   â”‚   â”œâ”€â”€ producer.js       # Job creation
â”‚   â”‚   â””â”€â”€ worker.js         # Job processing
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ delay.js          # Human-like timing
â”‚       â”œâ”€â”€ logger.js         # Structured logging
â”‚       â””â”€â”€ retry.js          # Retry with backoff
â””â”€â”€ scripts/
    â”œâ”€â”€ start-worker.js       # Worker startup
    â””â”€â”€ enqueue-job.js        # Job CLI tool
```

## Output Format

Jobs return JSON with the following structure:

```json
{
  "success": true,
  "keyword": "iphone 15",
  "totalProducts": 120,
  "pagesScraped": 5,
  "duration": 45000,
  "scrapedAt": "2024-01-15T10:30:00.000Z",
  "products": [
    {
      "name": "iPhone 15 Pro Max 256GB",
      "price": 21999000,
      "rating": 4.9,
      "soldCount": 1500,
      "shopName": "Apple Official Store",
      "shopLocation": "Jakarta Selatan",
      "productUrl": "https://www.tokopedia.com/...",
      "imageUrl": "https://images.tokopedia.net/...",
      "scrapedAt": "2024-01-15T10:30:00.000Z"
    }
  ]
}
```

## Anti-Detection Features

1. **Stealth Plugin**: Masks `navigator.webdriver` and other automation flags
2. **User Agent Rotation**: Random modern browser signatures
3. **Viewport Randomization**: Slight variations in screen size
4. **Human-Like Scrolling**:
   - Variable scroll distances (300-700px)
   - Smooth scrolling animation
   - Random delays between scrolls
   - 15% chance of "reading" pauses
   - Occasional scroll-back behavior
5. **Typing Simulation**: Random delays between keystrokes
6. **Request Headers**: Indonesian locale headers

## Error Handling

- **Automatic Retries**: 3 attempts with exponential backoff
- **Resilient Selectors**: Fallback chains for dynamic CSS classes
- **Graceful Degradation**: Logs warnings for missing fields, continues scraping
- **Circuit Breaker**: Stops scrolling after 3 consecutive no-content checks

## License

MIT
